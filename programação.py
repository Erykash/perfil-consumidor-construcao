# -*- coding: utf-8 -*-
"""PROGRAMAÇÃO.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YyCKDzPGFAQq8fmcIRZBrkQ6fIqRQJYj
"""

# -*- coding: utf-8 -*-
import requests
import pandas as pd
import numpy as np
from scipy.interpolate import interp1d
from statsmodels.tsa.arima.model import ARIMA
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# 01. Coleta de Dados via HTTP Requests
def baixar_dados_empresas():
    url = "https://apisidra.ibge.gov.br/values/t/1757/n1/all/v/all/p/all"
    headers = {"User-Agent": "Mozilla/5.0"}
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        with open("dados_empresas.json", "w", encoding="utf-8") as f:
            f.write(response.text)
        print("Dados das empresas salvos com sucesso!")
    else:
        print(f"Erro ao baixar os dados das empresas: {response.status_code} - {response.text}")

def baixar_dados_populacao():
    url = "https://ftp.ibge.gov.br/Projecao_da_Populacao/Projecao_da_Populacao_2018/projecoes_2018_populacao_2010_2060_20200406.xls"
    headers = {"User-Agent": "Mozilla/5.0"}
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        with open("projecao_populacao.xls", "wb") as f:
            f.write(response.content)
        print("Projeção populacional salva com sucesso!")
    else:
        print(f"Erro ao baixar os dados de população: {response.status_code} - {response.text}")

baixar_dados_empresas()
baixar_dados_populacao()

# 02. Interpretação e Interpolação de Dados
def interpolar_faixa_etaria(df):
    anos = np.arange(2010, 2021)
    df.columns = df.columns.str.strip()
    faixas_etarias = ["35-39", "40-44", "45-49", "50-54", "55-59"]
    faixas_etarias_relevantes = df[df.iloc[:, 0].isin(faixas_etarias)]
    valores = faixas_etarias_relevantes.iloc[:, 1:12].sum().values
    interp_func = interp1d(anos, valores, kind='linear', fill_value="extrapolate")
    valores_estimados = interp_func([2021, 2022])
    df_resultado = pd.DataFrame({'Ano': list(anos) + [2021, 2022],
                                 'População_38_58': list(valores) + list(valores_estimados)})
    return df_resultado

# 03. Processamento e Integração dos Dados
def processar_dados_empresas(dados_empresas, df_populacao):
    df_empresas = pd.DataFrame(dados_empresas)
    # Verificar a estrutura dos dados e extrair as colunas corretas
    if 'D1N' in df_empresas.columns and 'D3N' in df_empresas.columns and 'V' in df_empresas.columns:
        df_empresas = df_empresas[['D1N', 'D3N', 'V']]
        df_empresas.columns = ['Estado', 'Ano', 'Numero_de_Empresas']
        df_empresas['Ano'] = pd.to_numeric(df_empresas['Ano'], errors='coerce')
        df_empresas['Numero_de_Empresas'] = pd.to_numeric(df_empresas['Numero_de_Empresas'], errors='coerce')
        df_empresas = df_empresas.groupby(['Estado', 'Ano']).sum().reset_index()
    else:
        print("Estrutura dos dados das empresas não é a esperada.")
        return pd.DataFrame()

    df_populacao['Ano'] = pd.to_numeric(df_populacao['Ano'], errors='coerce')
    df_populacao['População_38_58'] = pd.to_numeric(df_populacao['População_38_58'], errors='coerce')
    df_empresas.fillna(0, inplace=True)
    df_populacao.fillna(0, inplace=True)
    df_completo = pd.merge(df_empresas, df_populacao, on='Ano')
    df_completo['Razao'] = df_completo['Numero_de_Empresas'] / df_completo['População_38_58']
    return df_completo

# 04. Análise da Série Temporal (2007-2022)
df_empresas_processado = processar_dados_empresas(pd.read_json("dados_empresas.json"), interpolar_faixa_etaria(pd.read_excel("projecao_populacao.xls")))
print(df_empresas_processado[['Estado', 'Ano', 'Numero_de_Empresas', 'População_38_58', 'Razao']].head())

# 05. Estimar Dados para 2021 e 2022
df_temporal = df_empresas_processado[['Ano', 'Razao']].dropna()
if not df_temporal.empty:
    model = ARIMA(df_temporal['Razao'], order=(1, 1, 1))
    model_fit = model.fit()
    forecast = model_fit.forecast(steps=2)
    forecast_2021_2022 = pd.DataFrame(forecast, columns=['Razao'], index=[2021, 2022])
    print("Previsão da Razão para 2021 e 2022:")
    print(forecast_2021_2022)
else:
    print("Dados insuficientes para previsão ARIMA.")

# 06. Análise dos Estados com Comportamento Similar
df_temporal_clean = df_empresas_processado[['Estado', 'Ano', 'Razao']].dropna()
if not df_temporal_clean.empty:
    df_pivot = df_temporal_clean.pivot(index='Ano', columns='Estado', values='Razao')
    wcss = []
    for k in range(1, 11):
        kmeans = KMeans(n_clusters=k, random_state=0, n_init=10)
        kmeans.fit(df_pivot.fillna(0))
        wcss.append(kmeans.inertia_)
    plt.plot(range(1, 11), wcss, marker='o')
    plt.xlabel('Número de Clusters (K)')
    plt.ylabel('WCSS')
    plt.title('Método do Cotovelo')
    plt.show()

    num_clusters = 4
    kmeans = KMeans(n_clusters=num_clusters, random_state=0, n_init=10)
    df_pivot['Cluster'] = kmeans.fit_predict(df_pivot.fillna(0))
    print("\nEstados Agrupados por Comportamento Similar:")
    print(df_pivot[['Cluster']].head())
else:
    print("Dados insuficientes para agrupamento.")

# 07. Identificação de Estados Saturados e com Oportunidades
if not df_temporal_clean.empty:
    df_avg_reason = df_temporal_clean.groupby('Estado')['Razao'].mean().sort_values()
    print("Estados com maior saturação (razão alta):")
    print(df_avg_reason.tail())
    print("\nEstados com maior oportunidade (razão baixa):")
    print(df_avg_reason.head())
else:
    print("Dados insuficientes para análise de saturação e oportunidades.")

# 08. Normalização dos Dados
if not df_empresas_processado.empty:
    features = ['Numero_de_Empresas', 'População_38_58', 'Razao']
    scaler = StandardScaler()
    df_empresas_processado[features] = scaler.fit_transform(df_empresas_processado[features])
    print(df_empresas_processado[features].head())
else:
    print("Dados insuficientes para normalização.")

# 09. Escolha do Número de Clusters (Método do Cotovelo)
if not df_empresas_processado.empty:
    wcss = []
    for k in range(1, 11):
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        kmeans.fit(df_empresas_processado[features])
        wcss.append(kmeans.inertia_)
    plt.plot(range(1, 11), wcss, marker='o')
    plt.xlabel('Número de Clusters (K)')
    plt.ylabel('WCSS')
    plt.title('Método do Cotovelo')
    plt.show()
else:
    print("Dados insuficientes para o método do cotovelo.")

# 10. Aplicação do PCA
if not df_empresas_processado.empty:
    X = df_empresas_processado[['Numero_de_Empresas', 'População_38_58', 'Razao']]
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(X)
    df_pca = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])
    df_pca['Estado'] = df_empresas_processado['Estado']
    df_pca['Ano'] = df_empresas_processado['Ano']
    print("Variância explicada por cada componente:", pca.explained_variance_ratio_)
    plt.figure(figsize=(10,6))
    plt.scatter(df_pca['PC1'], df_pca['PC2'], alpha=0.6)
    plt.xlabel('Componente Principal 1')
    plt.ylabel('Componente Principal 2')
    plt.title('Distribuição dos Estados Após PCA')
    plt.grid()
    plt.show()
else:
    print("Dados insuficientes para PCA.")

# 11. Clusterização com K-Means
if not df_pca.empty:
    num_clusters = 8
    kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)
    df_pca['Cluster'] = kmeans.fit_predict(df_pca[['PC1', 'PC2']])
    plt.figure(figsize=(10,6))
    for cluster in range(num_clusters):
        cluster_data = df_pca[df_pca['Cluster'] == cluster]
        plt.scatter(cluster_data['PC1'], cluster_data['PC2'], label=f'Cluster {cluster}')
    plt.xlabel('Componente Principal 1')
    plt.ylabel('Componente Principal 2')
    plt.title('Clusterização dos Estados com PCA + K-Means')
    plt.legend()
    plt.grid()
    plt.show()

    for i in range(num_clusters):
        print(f"Cluster {i}: {df_pca[df_pca['Cluster'] == i]['Estado'].unique()}")
else:
    print("Dados insuficientes para clusterização.")